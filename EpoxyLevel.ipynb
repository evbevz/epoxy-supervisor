{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb3e7134-3559-4489-b650-d4cbcf7ef649",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "#import numpy as np\n",
    "import os.path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Загрузка файла анотации в формате \"CVAT for images 1.1\"\n",
    "# Из файла берётся массив точек полилинии с разметкой шкалы деления: 0мл, 1мл, ... 20мл\n",
    "def Calibrate (fAnnotation):\n",
    "    tree = etree.parse(fAnnotation)\n",
    "    root = tree.getroot()\n",
    "    result = root.xpath('//polyline[@label=\"injector meter\"]')\n",
    "    if not(result):\n",
    "        raise Exception(\"Не удалось найти polyline с точками уровней инжектора в файле: \", fAnnotation)\n",
    "    points = result[0].attrib['points']\n",
    "    # Сложная конструкция, но по сути разбирает стороку на список списков (двумерный список) из двух значений попутно переводя из строковых значений в числовое значние.\n",
    "    list_of_points = list(map(lambda x: list(map(float,x.split(','))), points.split(';')))\n",
    "    # array_of_points = np.array(list_of_points) # Изначально думал работать в NumPy, но предсказания выдают значения в тензорах и потому решил тут тоже использовать тензоры\n",
    "    array_of_points = torch.tensor(list_of_points)\n",
    "    #print (array_of_points)\n",
    "    #return list_of_points\n",
    "    return array_of_points\n",
    "\n",
    "def GetEpoxyLevel (model, arrayEpoxyLevel, file):\n",
    "    # Запускаем предсказание\n",
    "    results = model.predict(source=filenameInjectorCam, verbose=False)  # Предсказание по изображению. Возвращается список результатов (т.к. можно передать список кадров или даже видео)\n",
    "    # Теоретически может быть список результатов, но берём только одно - первое.\n",
    "    keypoints = results[0].keypoints  # Keypoints object for pose outputs\n",
    "    #results[0].show()  # display to screen\n",
    "    #print ('--- Keypoints: ---\\n', keypoints)\n",
    "    \n",
    "    # Вычисляем середину диагоналей эллипса. На будущее стоит просто определять bounding box этого эллипса. Модель будет выдавать уже как раз середину.\n",
    "    # Проверяем уверенность в определении точки. Если показатель меньше заданного значения, то точку игнорируем.\n",
    "    #print (\"Keypoints.conf: \", keypoints.conf[0][2:6:]) \n",
    "    # Середина между левой и правой точками большой диагонали эллипса\n",
    "    if (keypoints.conf[0][2]>kptConfidence) and (keypoints.conf[0][3]>kptConfidence):\n",
    "        big_axis_center = (keypoints.xy[0][2] + keypoints.xy[0][3])/2\n",
    "    else:\n",
    "        big_axis_center = None\n",
    "    # Середина между дальней и ближней точками малой диагонали эллипса\n",
    "    if (keypoints.conf[0][4]>kptConfidence) and (keypoints.conf[0][5]>kptConfidence):\n",
    "        small_axis_center = (keypoints.xy[0][4] + keypoints.xy[0][5])/2\n",
    "    else:\n",
    "        small_axis_center = None\n",
    "    # Середина между серединой большой и серединой малой диагоналей. Иногда может быть не равная серединам каждой из них (при ошибках в определении ключевых точек моделью).\n",
    "    if (big_axis_center != None) and (small_axis_center != None):\n",
    "        ellipse_center = (big_axis_center + small_axis_center)/2\n",
    "    elif (big_axis_center != None) and (small_axis_center == None):\n",
    "        ellipse_center = big_axis_center\n",
    "    elif (big_axis_center == None) and (small_axis_center != None):\n",
    "        ellipse_center = small_axis_center\n",
    "    else:\n",
    "        ellipse_center = None\n",
    "    #print (\"BAC: \", big_axis_center, \"SAC: \", small_axis_center, \"ELC:\", ellipse_center)       \n",
    "    \n",
    "    if ellipse_center != None:\n",
    "        # Переносим массив точек шприца на то же устройство рассчета где и тензоры модели предсказаний. Если расчёты велись на CUDA, то лучше там и считать всё остальное.\n",
    "        arrayEpoxyLevel = arrayEpoxyLevel.to(ellipse_center.device)\n",
    "        \n",
    "        # Вычисляем ближайшую калиброванную точку к предсказанной точке (середине эллипса)\n",
    "        LengthMin = (keypoints.orig_shape[0]**2+keypoints.orig_shape[1]**2)**0.5 # Нужно просто большое значение, но решил указать максимально возможное расстояние на изображении (диагональ)\n",
    "        LevelMin = 0\n",
    "        for level, kpt in enumerate(arrayEpoxyLevel):\n",
    "            Length = torch.norm(ellipse_center - kpt) # Расстояние между предсказанной точкой и калиброванной точкой\n",
    "            if Length < LengthMin: # Если решим, что хоти чтобы при одинаковом расстоянии показывал значение большего уровня, то тогда поставить знак сравнения <=\n",
    "                LengthMin = Length # Запоминаем минимальное расстояние\n",
    "                LevelMin = level # Запоминаем уровень к точке которого расстояние минимальное\n",
    "            #print (\"Lvl: \", level, \"\\tCalib pt: \", kpt, \"\\tPredict pt: \", ellipse_center, \"\\tLength: \", Length)\n",
    "        #print (\"Предсказанный уровень эпоксидки: \", LevelMin)\n",
    "        return LevelMin\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Значение уверенности в правильности распознавания, ниже которого не будем считать, что точки определились правильно. Т.е. координаты такой точки будем считать ложными и точку игнорировать.\n",
    "kptConfidence = 0.8 # Сейчас точки если и распознаются, то с уверенностью больше 0.9\n",
    "\n",
    "# Калибровочный файл в котором хранятся уровни от 0 до 20мл. В виде координат X,Y центра эллипса поверхности эпоксидки на каждом уровне.\n",
    "filenameAnnotation = '/home/nikolay/opencv/epoxy-supervisor/samples/EpoxyLevelCalibrate.annotations.xml'\n",
    "\n",
    "# Файл весов обученной для распознавания модели\n",
    "filenameAIModel = '/home/nikolay/opencv/epoxy-supervisor/weights/epoxy-supervisor.20241228.best.pt'\n",
    "\n",
    "# Изображение для предсказания уровня эпоксидки\n",
    "filenameInjectorCam = '/home/nikolay/opencv/epoxy-supervisor/samples/fail01.png'\n",
    "#filenameInjectorCam = '/home/nikolay/opencv/epoxy-supervisor/datasets/epoxy-level-1774/images/test/000019.png'\n",
    "\n",
    "# Калибруем шприц\n",
    "arrayEpoxyLevel = Calibrate(filenameAnnotation)\n",
    "\n",
    "# Загружаем модель\n",
    "model = YOLO(filenameAIModel)\n",
    "\n",
    "# Запрос уровня по изображению\n",
    "GetEpoxyLevel(model, arrayEpoxyLevel, filenameInjectorCam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
